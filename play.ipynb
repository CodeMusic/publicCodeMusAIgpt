{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "torch.Size([50257, 768])\n",
      "transformer.wpe.weight\n",
      "torch.Size([1024, 768])\n",
      "transformer.h.0.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.0.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.0.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.0.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.1.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.1.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.1.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.1.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.2.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.2.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.2.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.2.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.3.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.3.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.3.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.3.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.4.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.4.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.4.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.4.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.5.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.5.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.5.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.5.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.5.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.6.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.6.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.6.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.6.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.6.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.6.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.7.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.7.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.7.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.7.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.7.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.7.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.8.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.8.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.8.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.8.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.8.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.8.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.9.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.9.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.9.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.9.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.10.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.10.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.10.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.10.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.11.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.11.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.11.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.11.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.ln_f.weight\n",
      "torch.Size([768])\n",
      "transformer.ln_f.bias\n",
      "torch.Size([768])\n",
      "lm_head.weight\n",
      "torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\") #124M\n",
    "sd_hf = model_hf.state_dict()\n",
    "\n",
    "for k, v in sd_hf.items():\n",
    "    print(k)\n",
    "    print(v.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "assistant"
    ]
   },
   "source": [
    "Here's the formatted output of the code you provided:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntransformer.wte.weight\\n\\ntransformer.wpe.weight\\n\\ntransformer.h.0.ln_1.weight\\n\\ntransformer.h.0.ln_1.bias\\n\\ntransformer.h.0.attn.c_attn.weight\\n\\ntransformer.h.0.attn.c_attn.bias\\n\\ntransformer.h.0.attn.c_proj.weight\\n\\ntransformer.h.0.attn.c_proj.bias\\n\\ntransformer.h.0.ln_2.weight\\n\\ntransformer.h.0.ln_2.bias\\n\\ntransformer.h.0.mlp.c_fc.weight\\n\\ntransformer.h.0.mlp.c_fc.bias\\n\\ntransformer.h.0.mlp.c_proj.weight\\n\\ntransformer.h.0.mlp.c_proj.bias\\n\\ntransformer.h.1.ln_1.weight\\n\\ntransformer.h.1.ln_1.bias\\n\\ntransformer.h.1.attn.c_attn.weight\\n\\ntransformer.h.1.attn.c_attn.bias\\n\\ntransformer.h.1.attn.c_proj.weight\\n\\ntransformer.h.1.attn.c_proj.bias\\n\\ntransformer.h.1.ln_2.weight\\n\\ntransformer.h.1.ln_2.bias\\n\\ntransformer.h.1.mlp.c_fc.weight\\n\\ntransformer.h.1.mlp.c_fc.bias\\n\\ntransformer.h.1.mlp.c_proj.weight\\n\\ntransformer.h.1.mlp.c_proj.bias\\n\\ntransformer.h.2.ln_1.weight\\n\\ntransformer.h.2.ln_1.bias\\n\\ntransformer.h.2.attn.c_attn.weight\\n\\ntransformer.h.2.attn.c_attn.bias\\n\\ntransformer.h.2.attn.c_proj.weight\\n\\ntransformer.h.2.attn.c_proj.bias\\n\\ntransformer.h.2.ln_2.weight\\n\\ntransformer.h.2.ln_2.bias\\n\\ntransformer.h.2.mlp.c_fc.weight\\n\\ntransformer.h.2.mlp.c_fc.bias\\n\\ntransformer.h.2.mlp.c_proj.weight\\n\\ntransformer.h.2.mlp.c_proj.bias\\n\\ntransformer.h.3.ln_1.weight\\n\\ntransformer.h.3.ln_1.bias\\n\\ntransformer.h.3.attn.c_attn.weight\\n\\ntransformer.h.3.attn.c_attn.bias\\n\\ntransformer.h.3.attn.c_proj.weight\\n\\ntransformer.h.3.attn.c_proj.bias\\n\\ntransformer.h.3.ln_2.weight\\n\\ntransformer.h.3.ln_2.bias\\n\\ntransformer.h.3.mlp.c_fc.weight\\n\\ntransformer.h.3.mlp.c_fc.bias\\n\\ntransformer.h.3.mlp.c_proj.weight\\n\\ntransformer.h.3.mlp.c_proj.bias\\n\\ntransformer.h.4.ln_1.weight\\n\\ntransformer.h.4.ln_1.bias\\n\\ntransformer.h.4.attn.c_attn.weight\\n\\ntransformer.h.4.attn.c_attn.bias\\n\\ntransformer.h.4.attn.c_proj.weight\\n\\ntransformer.h.4.attn.c_proj.bias\\n\\ntransformer.h.4.ln_2.weight\\n\\ntransformer.h.4.ln_2.bias\\n\\ntransformer.h.4.mlp.c_fc.weight\\n\\ntransformer.h.4.mlp.c_fc.bias\\n\\ntransformer.h.4.mlp.c_proj.weight\\n\\ntransformer.h.4.mlp.c_proj.bias\\n\\ntransformer.h.5.ln_1.weight\\n\\ntransformer.h.5.ln_1.bias\\n\\ntransformer.h.5.attn.c_attn.weight\\n\\ntransformer.h.5.attn.c_attn.bias\\n\\ntransformer.h.5.attn.c_proj.weight\\n\\ntransformer.h.5.attn.c_proj.bias\\n\\ntransformer.h.5.ln_2.weight\\n\\ntransformer.h.5.ln_2.bias\\n\\ntransformer.h.5.mlp.c_fc.weight\\n\\ntransformer.h.5.mlp.c_fc.bias\\n\\ntransformer.h.5.mlp.c_proj.weight\\n\\ntransformer.h.5.mlp.c_proj.bias\\n\\ntransformer.h.6.ln_1.weight\\n\\ntransformer.h.6.ln_1.bias\\n\\ntransformer.h.6.attn.c_attn.weight\\n\\ntransformer.h.6.attn.c_attn.bias\\n\\ntransformer.h.6.attn.c_proj.weight\\n\\ntransformer.h.6.attn.c_proj.bias\\n\\ntransformer.h.6.ln_2.weight\\n\\ntransformer.h.6.ln_2.bias\\n\\ntransformer.h.6.mlp.c_fc.weight\\n\\ntransformer.h.6.mlp.c_fc.bias\\n\\ntransformer.h.6.mlp.c_proj.weight\\n\\ntransformer.h.6.mlp.c_proj.bias\\n\\ntransformer.h.7.ln_1.weight\\n\\ntransformer.h.7.ln_1.bias\\n\\ntransformer.h.7.attn.c_attn.weight\\n\\ntransformer.h.7.attn.c_attn.bias\\n\\ntransformer.h.7.attn.c_proj.weight\\n\\ntransformer.h.7.attn.c_proj.bias\\n\\ntransformer.h.7.ln_2.weight\\n\\ntransformer.h.7.ln_2.bias\\n\\ntransformer.h.7.mlp.c_fc.weight\\n\\ntransformer.h.7.mlp.c_fc.bias\\n\\ntransformer.h.7.mlp.c_proj.weight\\n\\ntransformer.h.7.mlp.c_proj.bias\\n\\ntransformer.h.8.ln_1.weight\\n\\ntransformer.h.8.ln_1.bias\\n\\ntransformer.h.8.attn.c_attn.weight\\n\\ntransformer.h.8.attn.c_attn.bias\\n\\ntransformer.h.8.attn.c_proj.weight\\n\\ntransformer.h.8.attn.c_proj.bias\\n\\ntransformer.h.8.ln_2.weight\\n\\ntransformer.h.8.ln_2.bias\\n\\ntransformer.h.8.mlp.c_fc.weight\\n\\ntransformer.h.8.mlp.c_fc.bias\\n\\ntransformer.h.8.mlp.c_proj.weight\\n\\ntransformer.h.8.mlp.c_proj.bias\\n\\ntransformer.h.9.ln_1.weight\\n\\ntransformer.h.9.ln_1.bias\\n\\ntransformer.h.9.attn.c_attn.weight\\n\\ntransformer.h.9.attn.c_attn.bias\\n\\ntransformer.h.9.attn.c_proj.weight\\n\\ntransformer.h.9.attn.c_proj.bias\\n\\ntransformer.h.9.ln_2.weight\\n\\ntransformer.h.9.ln_2.bias\\n\\ntransformer.h.9.mlp.c_fc.weight\\n\\ntransformer.h.9.mlp.c_fc.bias\\n\\ntransformer.h.9.mlp.c_proj.weight\\n\\ntransformer.h.9.mlp.c_proj.bias\\n\\ntransformer.h.10.ln_1.weight\\n\\ntransformer.h.10.ln_1.bias\\n\\ntransformer.h.10.attn.c_attn.weight\\n\\ntransformer.h.10.attn.c_attn.bias\\n\\ntransformer.h.10.attn.c_proj.weight\\n\\ntransformer.h.10.attn.c_proj.bias\\n\\ntransformer.h.10.ln_2.weight\\n\\ntransformer.h.10.ln_2.bias\\n\\ntransformer.h.10.mlp.c_fc.weight\\n\\ntransformer.h.10.mlp.c_fc.bias\\n\\ntransformer.h.10.mlp.c_proj.weight\\n\\ntransformer.h.10.mlp.c_proj.bias\\n\\ntransformer.h.11.ln_1.weight\\n\\ntransformer.h.11.ln_1.bias\\n\\ntransformer.h.11.attn.c_attn.weight\\n\\ntransformer.h.11.attn.c_attn.bias\\n\\ntransformer.h.11.attn.c_proj.weight\\n\\ntransformer.h.11.attn.c_proj.bias\\n\\ntransformer.h.11.ln_2.weight\\n\\ntransformer.h.11.ln_2.bias\\n\\ntransformer.h.11.mlp.c_fc.weight\\n\\ntransformer.h.11.mlp.c_fc.bias\\n\\ntransformer.h.11.mlp.c_proj.weight\\n\\ntransformer.h.11.mlp.c_proj.bias\\n\\ntransformer.ln_f.weight\\n\\ntransformer.ln_f.bias\\n\\nlm_head.weight\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "transformer.wte.weight\n",
    "\n",
    "transformer.wpe.weight\n",
    "\n",
    "transformer.h.0.ln_1.weight\n",
    "\n",
    "transformer.h.0.ln_1.bias\n",
    "\n",
    "transformer.h.0.attn.c_attn.weight\n",
    "\n",
    "transformer.h.0.attn.c_attn.bias\n",
    "\n",
    "transformer.h.0.attn.c_proj.weight\n",
    "\n",
    "transformer.h.0.attn.c_proj.bias\n",
    "\n",
    "transformer.h.0.ln_2.weight\n",
    "\n",
    "transformer.h.0.ln_2.bias\n",
    "\n",
    "transformer.h.0.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.0.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.0.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.0.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.1.ln_1.weight\n",
    "\n",
    "transformer.h.1.ln_1.bias\n",
    "\n",
    "transformer.h.1.attn.c_attn.weight\n",
    "\n",
    "transformer.h.1.attn.c_attn.bias\n",
    "\n",
    "transformer.h.1.attn.c_proj.weight\n",
    "\n",
    "transformer.h.1.attn.c_proj.bias\n",
    "\n",
    "transformer.h.1.ln_2.weight\n",
    "\n",
    "transformer.h.1.ln_2.bias\n",
    "\n",
    "transformer.h.1.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.1.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.1.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.1.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.2.ln_1.weight\n",
    "\n",
    "transformer.h.2.ln_1.bias\n",
    "\n",
    "transformer.h.2.attn.c_attn.weight\n",
    "\n",
    "transformer.h.2.attn.c_attn.bias\n",
    "\n",
    "transformer.h.2.attn.c_proj.weight\n",
    "\n",
    "transformer.h.2.attn.c_proj.bias\n",
    "\n",
    "transformer.h.2.ln_2.weight\n",
    "\n",
    "transformer.h.2.ln_2.bias\n",
    "\n",
    "transformer.h.2.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.2.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.2.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.2.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.3.ln_1.weight\n",
    "\n",
    "transformer.h.3.ln_1.bias\n",
    "\n",
    "transformer.h.3.attn.c_attn.weight\n",
    "\n",
    "transformer.h.3.attn.c_attn.bias\n",
    "\n",
    "transformer.h.3.attn.c_proj.weight\n",
    "\n",
    "transformer.h.3.attn.c_proj.bias\n",
    "\n",
    "transformer.h.3.ln_2.weight\n",
    "\n",
    "transformer.h.3.ln_2.bias\n",
    "\n",
    "transformer.h.3.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.3.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.3.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.3.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.4.ln_1.weight\n",
    "\n",
    "transformer.h.4.ln_1.bias\n",
    "\n",
    "transformer.h.4.attn.c_attn.weight\n",
    "\n",
    "transformer.h.4.attn.c_attn.bias\n",
    "\n",
    "transformer.h.4.attn.c_proj.weight\n",
    "\n",
    "transformer.h.4.attn.c_proj.bias\n",
    "\n",
    "transformer.h.4.ln_2.weight\n",
    "\n",
    "transformer.h.4.ln_2.bias\n",
    "\n",
    "transformer.h.4.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.4.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.4.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.4.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.5.ln_1.weight\n",
    "\n",
    "transformer.h.5.ln_1.bias\n",
    "\n",
    "transformer.h.5.attn.c_attn.weight\n",
    "\n",
    "transformer.h.5.attn.c_attn.bias\n",
    "\n",
    "transformer.h.5.attn.c_proj.weight\n",
    "\n",
    "transformer.h.5.attn.c_proj.bias\n",
    "\n",
    "transformer.h.5.ln_2.weight\n",
    "\n",
    "transformer.h.5.ln_2.bias\n",
    "\n",
    "transformer.h.5.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.5.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.5.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.5.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.6.ln_1.weight\n",
    "\n",
    "transformer.h.6.ln_1.bias\n",
    "\n",
    "transformer.h.6.attn.c_attn.weight\n",
    "\n",
    "transformer.h.6.attn.c_attn.bias\n",
    "\n",
    "transformer.h.6.attn.c_proj.weight\n",
    "\n",
    "transformer.h.6.attn.c_proj.bias\n",
    "\n",
    "transformer.h.6.ln_2.weight\n",
    "\n",
    "transformer.h.6.ln_2.bias\n",
    "\n",
    "transformer.h.6.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.6.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.6.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.6.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.7.ln_1.weight\n",
    "\n",
    "transformer.h.7.ln_1.bias\n",
    "\n",
    "transformer.h.7.attn.c_attn.weight\n",
    "\n",
    "transformer.h.7.attn.c_attn.bias\n",
    "\n",
    "transformer.h.7.attn.c_proj.weight\n",
    "\n",
    "transformer.h.7.attn.c_proj.bias\n",
    "\n",
    "transformer.h.7.ln_2.weight\n",
    "\n",
    "transformer.h.7.ln_2.bias\n",
    "\n",
    "transformer.h.7.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.7.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.7.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.7.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.8.ln_1.weight\n",
    "\n",
    "transformer.h.8.ln_1.bias\n",
    "\n",
    "transformer.h.8.attn.c_attn.weight\n",
    "\n",
    "transformer.h.8.attn.c_attn.bias\n",
    "\n",
    "transformer.h.8.attn.c_proj.weight\n",
    "\n",
    "transformer.h.8.attn.c_proj.bias\n",
    "\n",
    "transformer.h.8.ln_2.weight\n",
    "\n",
    "transformer.h.8.ln_2.bias\n",
    "\n",
    "transformer.h.8.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.8.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.8.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.8.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.9.ln_1.weight\n",
    "\n",
    "transformer.h.9.ln_1.bias\n",
    "\n",
    "transformer.h.9.attn.c_attn.weight\n",
    "\n",
    "transformer.h.9.attn.c_attn.bias\n",
    "\n",
    "transformer.h.9.attn.c_proj.weight\n",
    "\n",
    "transformer.h.9.attn.c_proj.bias\n",
    "\n",
    "transformer.h.9.ln_2.weight\n",
    "\n",
    "transformer.h.9.ln_2.bias\n",
    "\n",
    "transformer.h.9.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.9.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.9.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.9.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.10.ln_1.weight\n",
    "\n",
    "transformer.h.10.ln_1.bias\n",
    "\n",
    "transformer.h.10.attn.c_attn.weight\n",
    "\n",
    "transformer.h.10.attn.c_attn.bias\n",
    "\n",
    "transformer.h.10.attn.c_proj.weight\n",
    "\n",
    "transformer.h.10.attn.c_proj.bias\n",
    "\n",
    "transformer.h.10.ln_2.weight\n",
    "\n",
    "transformer.h.10.ln_2.bias\n",
    "\n",
    "transformer.h.10.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.10.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.10.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.10.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.11.ln_1.weight\n",
    "\n",
    "transformer.h.11.ln_1.bias\n",
    "\n",
    "transformer.h.11.attn.c_attn.weight\n",
    "\n",
    "transformer.h.11.attn.c_attn.bias\n",
    "\n",
    "transformer.h.11.attn.c_proj.weight\n",
    "\n",
    "transformer.h.11.attn.c_proj.bias\n",
    "\n",
    "transformer.h.11.ln_2.weight\n",
    "\n",
    "transformer.h.11.ln_2.bias\n",
    "\n",
    "transformer.h.11.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.11.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.11.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.11.mlp.c_proj.bias\n",
    "\n",
    "transformer.ln_f.weight\n",
    "\n",
    "transformer.ln_f.bias\n",
    "\n",
    "lm_head.weight\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import random\n",
    "import math\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "class Value:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data)\n",
    "        else:  # Assume other is a float or int\n",
    "            return Value(self.data * other)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data + other.data)\n",
    "        else:  # Assume other is a float or int\n",
    "            return Value(self.data + other)\n",
    "\n",
    "    def tanh(self):\n",
    "        return Value(math.tanh(self.data))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value({self.data})\"\n",
    "    \n",
    "class Neuron:\n",
    "    def __init__(self, uin):\n",
    "        self.w = [Value(random.uniform(-1, 1)) for _ in range(uin)]\n",
    "        self.b = Value(random.uniform(-1, 1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Ensure x is a list of Value objects\n",
    "        x = [Value(xi) if not isinstance(xi, Value) else xi for xi in x]\n",
    "        # Initialize sum as a Value object with 0\n",
    "        act = Value(0)\n",
    "\n",
    "        print('Values in Input  ', len(x))\n",
    "\n",
    "        # Sum up all the weighted inputs\n",
    "        for wi, xi in zip(self.w, x):\n",
    "            print('Input ', xi, 'Weight', wi, 'Product', wi * xi, 'Previous Activation', act)\n",
    "            act = act + wi * xi  # xi is already a Value object\n",
    "            print('New Activation', act)\n",
    "\n",
    "        print('Bias', self.b)\n",
    "        act = act + self.b\n",
    "        print('** Final Activation', act, ' **')\n",
    "        out = act.tanh()\n",
    "        print('** Tanh Squash ', out, ' **')\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, nin, neurons):\n",
    "        self.neurons = [Neuron(nin) for _ in range(neurons)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        n = 0;\n",
    "        out = []\n",
    "        for neuron in self.neurons:\n",
    "            print('    --- Processing Neuron ', n)\n",
    "            out.append(neuron(x))\n",
    "            n += 1; \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, nin, nouts):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        n = 0;\n",
    "        for layer in self.layers:\n",
    "            print('>>> Processing Layer ', n)\n",
    "            x = layer(x)\n",
    "            n += 1\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in [2.0, 30, -1.0]\n",
      "params [Value(0.919070601336119), Value(0.6606473738750964), Value(-0.0023333685162900686), Value(-0.3297248546885154), Value(0.15767211612842735), Value(0.7653230767385126), Value(0.13353304987235304), Value(0.12249626441747519), Value(-0.7015819049074614), Value(0.9839695469735426), Value(-0.5104237869384975), Value(-0.5635344822128132), Value(0.5421206060821713), Value(-0.38011383531267295), Value(-0.4126385738082088), Value(-0.9456254616071622), Value(0.7590358481064183), Value(-0.42752021420428665), Value(-0.7801622576479286), Value(0.7231080608397127), Value(0.09097262026450426), Value(0.6144401202149881), Value(0.27972785062247896), Value(0.14718278752199532), Value(0.40989671411039263), Value(0.16819443759387154), Value(0.13140977347198834), Value(0.7233096694219943), Value(-0.4324533813270066), Value(-0.031814447433612836), Value(-0.543819106086898), Value(0.8155522327519238), Value(0.8651739447298403), Value(-0.4909268205693973), Value(0.15008388275384155), Value(-0.4226616828629315), Value(-0.9550639525078557), Value(0.7243565264300977), Value(0.34379377786228704), Value(0.45383496653548816), Value(0.4757921880126865)]\n",
      ">>> Processing Layer  0\n",
      "    --- Processing Neuron  0\n",
      "Values in Input   3\n",
      "Input  Value(2.0) Weight Value(0.919070601336119) Product Value(1.838141202672238) Previous Activation Value(0)\n",
      "New Activation Value(1.838141202672238)\n",
      "Input  Value(30) Weight Value(0.6606473738750964) Product Value(19.81942121625289) Previous Activation Value(1.838141202672238)\n",
      "New Activation Value(21.657562418925128)\n",
      "Input  Value(-1.0) Weight Value(-0.0023333685162900686) Product Value(0.0023333685162900686) Previous Activation Value(21.657562418925128)\n",
      "New Activation Value(21.659895787441418)\n",
      "Bias Value(-0.3297248546885154)\n",
      "** Final Activation Value(21.330170932752903)  **\n",
      "    --- Processing Neuron  1\n",
      "Values in Input   3\n",
      "Input  Value(2.0) Weight Value(0.15767211612842735) Product Value(0.3153442322568547) Previous Activation Value(0)\n",
      "New Activation Value(0.3153442322568547)\n",
      "Input  Value(30) Weight Value(0.7653230767385126) Product Value(22.95969230215538) Previous Activation Value(0.3153442322568547)\n",
      "New Activation Value(23.275036534412234)\n",
      "Input  Value(-1.0) Weight Value(0.13353304987235304) Product Value(-0.13353304987235304) Previous Activation Value(23.275036534412234)\n",
      "New Activation Value(23.141503484539882)\n",
      "Bias Value(0.12249626441747519)\n",
      "** Final Activation Value(23.263999748957357)  **\n",
      "    --- Processing Neuron  2\n",
      "Values in Input   3\n",
      "Input  Value(2.0) Weight Value(-0.7015819049074614) Product Value(-1.4031638098149228) Previous Activation Value(0)\n",
      "New Activation Value(-1.4031638098149228)\n",
      "Input  Value(30) Weight Value(0.9839695469735426) Product Value(29.519086409206277) Previous Activation Value(-1.4031638098149228)\n",
      "New Activation Value(28.115922599391354)\n",
      "Input  Value(-1.0) Weight Value(-0.5104237869384975) Product Value(0.5104237869384975) Previous Activation Value(28.115922599391354)\n",
      "New Activation Value(28.62634638632985)\n",
      "Bias Value(-0.5635344822128132)\n",
      "** Final Activation Value(28.062811904117037)  **\n",
      "    --- Processing Neuron  3\n",
      "Values in Input   3\n",
      "Input  Value(2.0) Weight Value(0.5421206060821713) Product Value(1.0842412121643425) Previous Activation Value(0)\n",
      "New Activation Value(1.0842412121643425)\n",
      "Input  Value(30) Weight Value(-0.38011383531267295) Product Value(-11.403415059380189) Previous Activation Value(1.0842412121643425)\n",
      "New Activation Value(-10.319173847215847)\n",
      "Input  Value(-1.0) Weight Value(-0.4126385738082088) Product Value(0.4126385738082088) Previous Activation Value(-10.319173847215847)\n",
      "New Activation Value(-9.906535273407638)\n",
      "Bias Value(-0.9456254616071622)\n",
      "** Final Activation Value(-10.8521607350148)  **\n",
      ">>> Processing Layer  1\n",
      "    --- Processing Neuron  0\n",
      "Values in Input   4\n",
      "Input  Value(1.0) Weight Value(0.7590358481064183) Product Value(0.7590358481064183) Previous Activation Value(0)\n",
      "New Activation Value(0.7590358481064183)\n",
      "Input  Value(1.0) Weight Value(-0.42752021420428665) Product Value(-0.42752021420428665) Previous Activation Value(0.7590358481064183)\n",
      "New Activation Value(0.3315156339021317)\n",
      "Input  Value(1.0) Weight Value(-0.7801622576479286) Product Value(-0.7801622576479286) Previous Activation Value(0.3315156339021317)\n",
      "New Activation Value(-0.4486466237457969)\n",
      "Input  Value(-0.9999999992501698) Weight Value(0.7231080608397127) Product Value(-0.7231080602975044) Previous Activation Value(-0.4486466237457969)\n",
      "New Activation Value(-1.1717546840433013)\n",
      "Bias Value(0.09097262026450426)\n",
      "** Final Activation Value(-1.080782063778797)  **\n",
      "    --- Processing Neuron  1\n",
      "Values in Input   4\n",
      "Input  Value(1.0) Weight Value(0.6144401202149881) Product Value(0.6144401202149881) Previous Activation Value(0)\n",
      "New Activation Value(0.6144401202149881)\n",
      "Input  Value(1.0) Weight Value(0.27972785062247896) Product Value(0.27972785062247896) Previous Activation Value(0.6144401202149881)\n",
      "New Activation Value(0.894167970837467)\n",
      "Input  Value(1.0) Weight Value(0.14718278752199532) Product Value(0.14718278752199532) Previous Activation Value(0.894167970837467)\n",
      "New Activation Value(1.0413507583594623)\n",
      "Input  Value(-0.9999999992501698) Weight Value(0.40989671411039263) Product Value(-0.4098967138030397) Previous Activation Value(1.0413507583594623)\n",
      "New Activation Value(0.6314540445564226)\n",
      "Bias Value(0.16819443759387154)\n",
      "** Final Activation Value(0.7996484821502942)  **\n",
      "    --- Processing Neuron  2\n",
      "Values in Input   4\n",
      "Input  Value(1.0) Weight Value(0.13140977347198834) Product Value(0.13140977347198834) Previous Activation Value(0)\n",
      "New Activation Value(0.13140977347198834)\n",
      "Input  Value(1.0) Weight Value(0.7233096694219943) Product Value(0.7233096694219943) Previous Activation Value(0.13140977347198834)\n",
      "New Activation Value(0.8547194428939826)\n",
      "Input  Value(1.0) Weight Value(-0.4324533813270066) Product Value(-0.4324533813270066) Previous Activation Value(0.8547194428939826)\n",
      "New Activation Value(0.422266061566976)\n",
      "Input  Value(-0.9999999992501698) Weight Value(-0.031814447433612836) Product Value(0.031814447409757404) Previous Activation Value(0.422266061566976)\n",
      "New Activation Value(0.4540805089767334)\n",
      "Bias Value(-0.543819106086898)\n",
      "** Final Activation Value(-0.08973859711016458)  **\n",
      "    --- Processing Neuron  3\n",
      "Values in Input   4\n",
      "Input  Value(1.0) Weight Value(0.8155522327519238) Product Value(0.8155522327519238) Previous Activation Value(0)\n",
      "New Activation Value(0.8155522327519238)\n",
      "Input  Value(1.0) Weight Value(0.8651739447298403) Product Value(0.8651739447298403) Previous Activation Value(0.8155522327519238)\n",
      "New Activation Value(1.6807261774817641)\n",
      "Input  Value(1.0) Weight Value(-0.4909268205693973) Product Value(-0.4909268205693973) Previous Activation Value(1.6807261774817641)\n",
      "New Activation Value(1.1897993569123668)\n",
      "Input  Value(-0.9999999992501698) Weight Value(0.15008388275384155) Product Value(-0.15008388264130412) Previous Activation Value(1.1897993569123668)\n",
      "New Activation Value(1.0397154742710626)\n",
      "Bias Value(-0.4226616828629315)\n",
      "** Final Activation Value(0.6170537914081311)  **\n",
      ">>> Processing Layer  2\n",
      "    --- Processing Neuron  0\n",
      "Values in Input   4\n",
      "Input  Value(-0.7934889340010819) Weight Value(-0.9550639525078557) Product Value(0.7578326775783183) Previous Activation Value(0)\n",
      "New Activation Value(0.7578326775783183)\n",
      "Input  Value(0.6638402065234549) Weight Value(0.7243565264300977) Product Value(0.4808569861019685) Previous Activation Value(0.7578326775783183)\n",
      "New Activation Value(1.2386896636802867)\n",
      "Input  Value(-0.08949848176112499) Weight Value(0.34379377786228704) Product Value(-0.030769021157596152) Previous Activation Value(1.2386896636802867)\n",
      "New Activation Value(1.2079206425226905)\n",
      "Input  Value(0.5490733772716004) Weight Value(0.45383496653548816) Product Value(0.24918869779958425) Previous Activation Value(1.2079206425226905)\n",
      "New Activation Value(1.4571093403222748)\n",
      "Bias Value(0.4757921880126865)\n",
      "** Final Activation Value(1.9329015283349613)  **\n",
      "out [Value(0.9589672855655215)]\n"
     ]
    }
   ],
   "source": [
    "x = [2.0, 30, -1.0]\n",
    "n = MLP(3, [4, 4, 1])\n",
    "\n",
    "print('in', x)\n",
    "print('params', n.parameters())\n",
    "\n",
    "out = n(x)\n",
    "print('out', out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
