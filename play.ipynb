{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "torch.Size([50257, 768])\n",
      "transformer.wpe.weight\n",
      "torch.Size([1024, 768])\n",
      "transformer.h.0.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.0.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.0.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.0.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.1.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.1.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.1.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.1.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.2.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.2.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.2.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.2.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.3.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.3.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.3.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.3.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.4.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.4.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.4.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.4.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.5.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.5.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.5.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.5.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.5.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.6.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.6.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.6.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.6.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.6.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.6.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.7.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.7.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.7.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.7.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.7.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.7.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.8.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.8.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.8.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.8.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.8.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.8.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.9.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.9.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.9.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.9.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.10.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.10.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.10.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.10.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.11.ln_1.weight\n",
      "torch.Size([768])\n",
      "transformer.h.11.ln_1.bias\n",
      "torch.Size([768])\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "torch.Size([768, 2304])\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "torch.Size([2304])\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "torch.Size([768, 768])\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.h.11.ln_2.weight\n",
      "torch.Size([768])\n",
      "transformer.h.11.ln_2.bias\n",
      "torch.Size([768])\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "torch.Size([768, 3072])\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "torch.Size([3072])\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "torch.Size([3072, 768])\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "torch.Size([768])\n",
      "transformer.ln_f.weight\n",
      "torch.Size([768])\n",
      "transformer.ln_f.bias\n",
      "torch.Size([768])\n",
      "lm_head.weight\n",
      "torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\") #124M\n",
    "sd_hf = model_hf.state_dict()\n",
    "\n",
    "for k, v in sd_hf.items():\n",
    "    print(k)\n",
    "    print(v.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "assistant"
    ]
   },
   "source": [
    "Here's the formatted output of the code you provided:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntransformer.wte.weight\\n\\ntransformer.wpe.weight\\n\\ntransformer.h.0.ln_1.weight\\n\\ntransformer.h.0.ln_1.bias\\n\\ntransformer.h.0.attn.c_attn.weight\\n\\ntransformer.h.0.attn.c_attn.bias\\n\\ntransformer.h.0.attn.c_proj.weight\\n\\ntransformer.h.0.attn.c_proj.bias\\n\\ntransformer.h.0.ln_2.weight\\n\\ntransformer.h.0.ln_2.bias\\n\\ntransformer.h.0.mlp.c_fc.weight\\n\\ntransformer.h.0.mlp.c_fc.bias\\n\\ntransformer.h.0.mlp.c_proj.weight\\n\\ntransformer.h.0.mlp.c_proj.bias\\n\\ntransformer.h.1.ln_1.weight\\n\\ntransformer.h.1.ln_1.bias\\n\\ntransformer.h.1.attn.c_attn.weight\\n\\ntransformer.h.1.attn.c_attn.bias\\n\\ntransformer.h.1.attn.c_proj.weight\\n\\ntransformer.h.1.attn.c_proj.bias\\n\\ntransformer.h.1.ln_2.weight\\n\\ntransformer.h.1.ln_2.bias\\n\\ntransformer.h.1.mlp.c_fc.weight\\n\\ntransformer.h.1.mlp.c_fc.bias\\n\\ntransformer.h.1.mlp.c_proj.weight\\n\\ntransformer.h.1.mlp.c_proj.bias\\n\\ntransformer.h.2.ln_1.weight\\n\\ntransformer.h.2.ln_1.bias\\n\\ntransformer.h.2.attn.c_attn.weight\\n\\ntransformer.h.2.attn.c_attn.bias\\n\\ntransformer.h.2.attn.c_proj.weight\\n\\ntransformer.h.2.attn.c_proj.bias\\n\\ntransformer.h.2.ln_2.weight\\n\\ntransformer.h.2.ln_2.bias\\n\\ntransformer.h.2.mlp.c_fc.weight\\n\\ntransformer.h.2.mlp.c_fc.bias\\n\\ntransformer.h.2.mlp.c_proj.weight\\n\\ntransformer.h.2.mlp.c_proj.bias\\n\\ntransformer.h.3.ln_1.weight\\n\\ntransformer.h.3.ln_1.bias\\n\\ntransformer.h.3.attn.c_attn.weight\\n\\ntransformer.h.3.attn.c_attn.bias\\n\\ntransformer.h.3.attn.c_proj.weight\\n\\ntransformer.h.3.attn.c_proj.bias\\n\\ntransformer.h.3.ln_2.weight\\n\\ntransformer.h.3.ln_2.bias\\n\\ntransformer.h.3.mlp.c_fc.weight\\n\\ntransformer.h.3.mlp.c_fc.bias\\n\\ntransformer.h.3.mlp.c_proj.weight\\n\\ntransformer.h.3.mlp.c_proj.bias\\n\\ntransformer.h.4.ln_1.weight\\n\\ntransformer.h.4.ln_1.bias\\n\\ntransformer.h.4.attn.c_attn.weight\\n\\ntransformer.h.4.attn.c_attn.bias\\n\\ntransformer.h.4.attn.c_proj.weight\\n\\ntransformer.h.4.attn.c_proj.bias\\n\\ntransformer.h.4.ln_2.weight\\n\\ntransformer.h.4.ln_2.bias\\n\\ntransformer.h.4.mlp.c_fc.weight\\n\\ntransformer.h.4.mlp.c_fc.bias\\n\\ntransformer.h.4.mlp.c_proj.weight\\n\\ntransformer.h.4.mlp.c_proj.bias\\n\\ntransformer.h.5.ln_1.weight\\n\\ntransformer.h.5.ln_1.bias\\n\\ntransformer.h.5.attn.c_attn.weight\\n\\ntransformer.h.5.attn.c_attn.bias\\n\\ntransformer.h.5.attn.c_proj.weight\\n\\ntransformer.h.5.attn.c_proj.bias\\n\\ntransformer.h.5.ln_2.weight\\n\\ntransformer.h.5.ln_2.bias\\n\\ntransformer.h.5.mlp.c_fc.weight\\n\\ntransformer.h.5.mlp.c_fc.bias\\n\\ntransformer.h.5.mlp.c_proj.weight\\n\\ntransformer.h.5.mlp.c_proj.bias\\n\\ntransformer.h.6.ln_1.weight\\n\\ntransformer.h.6.ln_1.bias\\n\\ntransformer.h.6.attn.c_attn.weight\\n\\ntransformer.h.6.attn.c_attn.bias\\n\\ntransformer.h.6.attn.c_proj.weight\\n\\ntransformer.h.6.attn.c_proj.bias\\n\\ntransformer.h.6.ln_2.weight\\n\\ntransformer.h.6.ln_2.bias\\n\\ntransformer.h.6.mlp.c_fc.weight\\n\\ntransformer.h.6.mlp.c_fc.bias\\n\\ntransformer.h.6.mlp.c_proj.weight\\n\\ntransformer.h.6.mlp.c_proj.bias\\n\\ntransformer.h.7.ln_1.weight\\n\\ntransformer.h.7.ln_1.bias\\n\\ntransformer.h.7.attn.c_attn.weight\\n\\ntransformer.h.7.attn.c_attn.bias\\n\\ntransformer.h.7.attn.c_proj.weight\\n\\ntransformer.h.7.attn.c_proj.bias\\n\\ntransformer.h.7.ln_2.weight\\n\\ntransformer.h.7.ln_2.bias\\n\\ntransformer.h.7.mlp.c_fc.weight\\n\\ntransformer.h.7.mlp.c_fc.bias\\n\\ntransformer.h.7.mlp.c_proj.weight\\n\\ntransformer.h.7.mlp.c_proj.bias\\n\\ntransformer.h.8.ln_1.weight\\n\\ntransformer.h.8.ln_1.bias\\n\\ntransformer.h.8.attn.c_attn.weight\\n\\ntransformer.h.8.attn.c_attn.bias\\n\\ntransformer.h.8.attn.c_proj.weight\\n\\ntransformer.h.8.attn.c_proj.bias\\n\\ntransformer.h.8.ln_2.weight\\n\\ntransformer.h.8.ln_2.bias\\n\\ntransformer.h.8.mlp.c_fc.weight\\n\\ntransformer.h.8.mlp.c_fc.bias\\n\\ntransformer.h.8.mlp.c_proj.weight\\n\\ntransformer.h.8.mlp.c_proj.bias\\n\\ntransformer.h.9.ln_1.weight\\n\\ntransformer.h.9.ln_1.bias\\n\\ntransformer.h.9.attn.c_attn.weight\\n\\ntransformer.h.9.attn.c_attn.bias\\n\\ntransformer.h.9.attn.c_proj.weight\\n\\ntransformer.h.9.attn.c_proj.bias\\n\\ntransformer.h.9.ln_2.weight\\n\\ntransformer.h.9.ln_2.bias\\n\\ntransformer.h.9.mlp.c_fc.weight\\n\\ntransformer.h.9.mlp.c_fc.bias\\n\\ntransformer.h.9.mlp.c_proj.weight\\n\\ntransformer.h.9.mlp.c_proj.bias\\n\\ntransformer.h.10.ln_1.weight\\n\\ntransformer.h.10.ln_1.bias\\n\\ntransformer.h.10.attn.c_attn.weight\\n\\ntransformer.h.10.attn.c_attn.bias\\n\\ntransformer.h.10.attn.c_proj.weight\\n\\ntransformer.h.10.attn.c_proj.bias\\n\\ntransformer.h.10.ln_2.weight\\n\\ntransformer.h.10.ln_2.bias\\n\\ntransformer.h.10.mlp.c_fc.weight\\n\\ntransformer.h.10.mlp.c_fc.bias\\n\\ntransformer.h.10.mlp.c_proj.weight\\n\\ntransformer.h.10.mlp.c_proj.bias\\n\\ntransformer.h.11.ln_1.weight\\n\\ntransformer.h.11.ln_1.bias\\n\\ntransformer.h.11.attn.c_attn.weight\\n\\ntransformer.h.11.attn.c_attn.bias\\n\\ntransformer.h.11.attn.c_proj.weight\\n\\ntransformer.h.11.attn.c_proj.bias\\n\\ntransformer.h.11.ln_2.weight\\n\\ntransformer.h.11.ln_2.bias\\n\\ntransformer.h.11.mlp.c_fc.weight\\n\\ntransformer.h.11.mlp.c_fc.bias\\n\\ntransformer.h.11.mlp.c_proj.weight\\n\\ntransformer.h.11.mlp.c_proj.bias\\n\\ntransformer.ln_f.weight\\n\\ntransformer.ln_f.bias\\n\\nlm_head.weight\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "transformer.wte.weight\n",
    "\n",
    "transformer.wpe.weight\n",
    "\n",
    "transformer.h.0.ln_1.weight\n",
    "\n",
    "transformer.h.0.ln_1.bias\n",
    "\n",
    "transformer.h.0.attn.c_attn.weight\n",
    "\n",
    "transformer.h.0.attn.c_attn.bias\n",
    "\n",
    "transformer.h.0.attn.c_proj.weight\n",
    "\n",
    "transformer.h.0.attn.c_proj.bias\n",
    "\n",
    "transformer.h.0.ln_2.weight\n",
    "\n",
    "transformer.h.0.ln_2.bias\n",
    "\n",
    "transformer.h.0.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.0.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.0.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.0.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.1.ln_1.weight\n",
    "\n",
    "transformer.h.1.ln_1.bias\n",
    "\n",
    "transformer.h.1.attn.c_attn.weight\n",
    "\n",
    "transformer.h.1.attn.c_attn.bias\n",
    "\n",
    "transformer.h.1.attn.c_proj.weight\n",
    "\n",
    "transformer.h.1.attn.c_proj.bias\n",
    "\n",
    "transformer.h.1.ln_2.weight\n",
    "\n",
    "transformer.h.1.ln_2.bias\n",
    "\n",
    "transformer.h.1.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.1.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.1.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.1.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.2.ln_1.weight\n",
    "\n",
    "transformer.h.2.ln_1.bias\n",
    "\n",
    "transformer.h.2.attn.c_attn.weight\n",
    "\n",
    "transformer.h.2.attn.c_attn.bias\n",
    "\n",
    "transformer.h.2.attn.c_proj.weight\n",
    "\n",
    "transformer.h.2.attn.c_proj.bias\n",
    "\n",
    "transformer.h.2.ln_2.weight\n",
    "\n",
    "transformer.h.2.ln_2.bias\n",
    "\n",
    "transformer.h.2.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.2.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.2.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.2.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.3.ln_1.weight\n",
    "\n",
    "transformer.h.3.ln_1.bias\n",
    "\n",
    "transformer.h.3.attn.c_attn.weight\n",
    "\n",
    "transformer.h.3.attn.c_attn.bias\n",
    "\n",
    "transformer.h.3.attn.c_proj.weight\n",
    "\n",
    "transformer.h.3.attn.c_proj.bias\n",
    "\n",
    "transformer.h.3.ln_2.weight\n",
    "\n",
    "transformer.h.3.ln_2.bias\n",
    "\n",
    "transformer.h.3.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.3.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.3.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.3.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.4.ln_1.weight\n",
    "\n",
    "transformer.h.4.ln_1.bias\n",
    "\n",
    "transformer.h.4.attn.c_attn.weight\n",
    "\n",
    "transformer.h.4.attn.c_attn.bias\n",
    "\n",
    "transformer.h.4.attn.c_proj.weight\n",
    "\n",
    "transformer.h.4.attn.c_proj.bias\n",
    "\n",
    "transformer.h.4.ln_2.weight\n",
    "\n",
    "transformer.h.4.ln_2.bias\n",
    "\n",
    "transformer.h.4.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.4.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.4.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.4.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.5.ln_1.weight\n",
    "\n",
    "transformer.h.5.ln_1.bias\n",
    "\n",
    "transformer.h.5.attn.c_attn.weight\n",
    "\n",
    "transformer.h.5.attn.c_attn.bias\n",
    "\n",
    "transformer.h.5.attn.c_proj.weight\n",
    "\n",
    "transformer.h.5.attn.c_proj.bias\n",
    "\n",
    "transformer.h.5.ln_2.weight\n",
    "\n",
    "transformer.h.5.ln_2.bias\n",
    "\n",
    "transformer.h.5.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.5.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.5.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.5.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.6.ln_1.weight\n",
    "\n",
    "transformer.h.6.ln_1.bias\n",
    "\n",
    "transformer.h.6.attn.c_attn.weight\n",
    "\n",
    "transformer.h.6.attn.c_attn.bias\n",
    "\n",
    "transformer.h.6.attn.c_proj.weight\n",
    "\n",
    "transformer.h.6.attn.c_proj.bias\n",
    "\n",
    "transformer.h.6.ln_2.weight\n",
    "\n",
    "transformer.h.6.ln_2.bias\n",
    "\n",
    "transformer.h.6.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.6.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.6.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.6.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.7.ln_1.weight\n",
    "\n",
    "transformer.h.7.ln_1.bias\n",
    "\n",
    "transformer.h.7.attn.c_attn.weight\n",
    "\n",
    "transformer.h.7.attn.c_attn.bias\n",
    "\n",
    "transformer.h.7.attn.c_proj.weight\n",
    "\n",
    "transformer.h.7.attn.c_proj.bias\n",
    "\n",
    "transformer.h.7.ln_2.weight\n",
    "\n",
    "transformer.h.7.ln_2.bias\n",
    "\n",
    "transformer.h.7.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.7.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.7.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.7.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.8.ln_1.weight\n",
    "\n",
    "transformer.h.8.ln_1.bias\n",
    "\n",
    "transformer.h.8.attn.c_attn.weight\n",
    "\n",
    "transformer.h.8.attn.c_attn.bias\n",
    "\n",
    "transformer.h.8.attn.c_proj.weight\n",
    "\n",
    "transformer.h.8.attn.c_proj.bias\n",
    "\n",
    "transformer.h.8.ln_2.weight\n",
    "\n",
    "transformer.h.8.ln_2.bias\n",
    "\n",
    "transformer.h.8.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.8.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.8.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.8.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.9.ln_1.weight\n",
    "\n",
    "transformer.h.9.ln_1.bias\n",
    "\n",
    "transformer.h.9.attn.c_attn.weight\n",
    "\n",
    "transformer.h.9.attn.c_attn.bias\n",
    "\n",
    "transformer.h.9.attn.c_proj.weight\n",
    "\n",
    "transformer.h.9.attn.c_proj.bias\n",
    "\n",
    "transformer.h.9.ln_2.weight\n",
    "\n",
    "transformer.h.9.ln_2.bias\n",
    "\n",
    "transformer.h.9.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.9.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.9.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.9.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.10.ln_1.weight\n",
    "\n",
    "transformer.h.10.ln_1.bias\n",
    "\n",
    "transformer.h.10.attn.c_attn.weight\n",
    "\n",
    "transformer.h.10.attn.c_attn.bias\n",
    "\n",
    "transformer.h.10.attn.c_proj.weight\n",
    "\n",
    "transformer.h.10.attn.c_proj.bias\n",
    "\n",
    "transformer.h.10.ln_2.weight\n",
    "\n",
    "transformer.h.10.ln_2.bias\n",
    "\n",
    "transformer.h.10.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.10.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.10.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.10.mlp.c_proj.bias\n",
    "\n",
    "transformer.h.11.ln_1.weight\n",
    "\n",
    "transformer.h.11.ln_1.bias\n",
    "\n",
    "transformer.h.11.attn.c_attn.weight\n",
    "\n",
    "transformer.h.11.attn.c_attn.bias\n",
    "\n",
    "transformer.h.11.attn.c_proj.weight\n",
    "\n",
    "transformer.h.11.attn.c_proj.bias\n",
    "\n",
    "transformer.h.11.ln_2.weight\n",
    "\n",
    "transformer.h.11.ln_2.bias\n",
    "\n",
    "transformer.h.11.mlp.c_fc.weight\n",
    "\n",
    "transformer.h.11.mlp.c_fc.bias\n",
    "\n",
    "transformer.h.11.mlp.c_proj.weight\n",
    "\n",
    "transformer.h.11.mlp.c_proj.bias\n",
    "\n",
    "transformer.ln_f.weight\n",
    "\n",
    "transformer.ln_f.bias\n",
    "\n",
    "lm_head.weight\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import random\n",
    "import math\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "#\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Value:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data)\n",
    "        else:  # Assume other is a float or int\n",
    "            return Value(self.data * other)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data + other.data)\n",
    "        else:  # Assume other is a float or int\n",
    "            return Value(self.data + other)\n",
    "\n",
    "    def tanh(self):\n",
    "        return Value(math.tanh(self.data))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value({self.data})\"\n",
    "    \n",
    "    def __float__(self):\n",
    "        return self.data\n",
    "    \n",
    "class Neuron(nn.Module):\n",
    "    def __init__(self, uin):\n",
    "        self.w = [Value(random.uniform(-1, 1)) for _ in range(uin)]\n",
    "        self.b = Value(random.uniform(-1, 1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Ensure x is a list of Value objects\n",
    "        x = [Value(xi) if not isinstance(xi, Value) else xi for xi in x]\n",
    "        # Initialize sum as a Value object with 0\n",
    "        act = Value(0)\n",
    "\n",
    "        print('Values in Input  ', len(x))\n",
    "\n",
    "        # Sum up all the weighted inputs\n",
    "        for wi, xi in zip(self.w, x):\n",
    "            print('Input ', xi, 'Weight', wi, 'Product', wi * xi, 'Previous Activation', act)\n",
    "            act = act + wi * xi  # xi is already a Value object\n",
    "            print('New Activation', act)\n",
    "\n",
    "        print('Bias', self.b)\n",
    "        act = act + self.b\n",
    "        print('** Final Activation', act, ' **')\n",
    "        out = act.tanh()\n",
    "        print('** Tanh Squash ', out, ' **')\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, nin, neurons):\n",
    "        self.neurons = [Neuron(nin) for _ in range(neurons)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        n = 0;\n",
    "        out = []\n",
    "        for neuron in self.neurons:\n",
    "            print('    --- Processing Neuron ', n)\n",
    "            out.append(neuron(x))\n",
    "            n += 1; \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, nin, nouts):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "    \n",
    "    def __call__(self, x, targets=None):\n",
    "        n = 0;\n",
    "        for layer in self.layers:\n",
    "            print('>>> Processing Layer ', n)\n",
    "            x = layer(x)\n",
    "            n += 1\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = torch.tensor(x, dtype=torch.float32)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "            print('Loss calculated successfully:', loss)\n",
    "\n",
    "        return x, loss\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in [0.5, 1, -1.0]\n",
      "params [Value(-0.7937687192887855), Value(0.8937414476248975), Value(-0.3557851217519128), Value(0.6108232612173714), Value(-0.773616342747111), Value(-0.4492922645408297), Value(0.6327685945205659), Value(0.7090023653019686), Value(0.6594792396583944), Value(-0.8592055392960882), Value(0.29885690130957654), Value(0.9172579793091433), Value(-0.23653336516778944), Value(0.018092595814938273), Value(0.5805888443120657), Value(-0.2981630720614945), Value(-0.366441682366059), Value(0.6439097970588255), Value(0.34201765484501867), Value(-0.5036751628717546), Value(0.4379724264058984), Value(-0.5341524680540122), Value(0.5220947239083467), Value(-0.4444135698859719), Value(-0.15342687266425425), Value(-0.6357519028783745), Value(0.10436345678979109), Value(-0.7708247304454754), Value(-0.006340167987510137), Value(-0.219071552168433), Value(-0.11593475777548101), Value(0.4691487942897299), Value(-0.07350603888393681), Value(-0.7802592358676796), Value(0.9378700820417687), Value(-0.635178669888707), Value(0.3882156416731124), Value(0.37283093924666866), Value(-0.8818853961896111), Value(0.5930932700205547), Value(-0.03497588823930142)]\n",
      ">>> Processing Layer  0\n",
      "    --- Processing Neuron  0\n",
      "Values in Input   3\n",
      "Input  Value(0.5) Weight Value(-0.7937687192887855) Product Value(-0.3968843596443927) Previous Activation Value(0)\n",
      "New Activation Value(-0.3968843596443927)\n",
      "Input  Value(1) Weight Value(0.8937414476248975) Product Value(0.8937414476248975) Previous Activation Value(-0.3968843596443927)\n",
      "New Activation Value(0.49685708798050476)\n",
      "Input  Value(-1.0) Weight Value(-0.3557851217519128) Product Value(0.3557851217519128) Previous Activation Value(0.49685708798050476)\n",
      "New Activation Value(0.8526422097324176)\n",
      "Bias Value(0.6108232612173714)\n",
      "** Final Activation Value(1.463465470949789)  **\n",
      "** Tanh Squash  Value(0.8983235713436679)  **\n",
      "    --- Processing Neuron  1\n",
      "Values in Input   3\n",
      "Input  Value(0.5) Weight Value(-0.773616342747111) Product Value(-0.3868081713735555) Previous Activation Value(0)\n",
      "New Activation Value(-0.3868081713735555)\n",
      "Input  Value(1) Weight Value(-0.4492922645408297) Product Value(-0.4492922645408297) Previous Activation Value(-0.3868081713735555)\n",
      "New Activation Value(-0.8361004359143852)\n",
      "Input  Value(-1.0) Weight Value(0.6327685945205659) Product Value(-0.6327685945205659) Previous Activation Value(-0.8361004359143852)\n",
      "New Activation Value(-1.4688690304349512)\n",
      "Bias Value(0.7090023653019686)\n",
      "** Final Activation Value(-0.7598666651329826)  **\n",
      "** Tanh Squash  Value(-0.6409984175247144)  **\n",
      "    --- Processing Neuron  2\n",
      "Values in Input   3\n",
      "Input  Value(0.5) Weight Value(0.6594792396583944) Product Value(0.3297396198291972) Previous Activation Value(0)\n",
      "New Activation Value(0.3297396198291972)\n",
      "Input  Value(1) Weight Value(-0.8592055392960882) Product Value(-0.8592055392960882) Previous Activation Value(0.3297396198291972)\n",
      "New Activation Value(-0.529465919466891)\n",
      "Input  Value(-1.0) Weight Value(0.29885690130957654) Product Value(-0.29885690130957654) Previous Activation Value(-0.529465919466891)\n",
      "New Activation Value(-0.8283228207764676)\n",
      "Bias Value(0.9172579793091433)\n",
      "** Final Activation Value(0.08893515853267575)  **\n",
      "** Tanh Squash  Value(0.08870142156682637)  **\n",
      "    --- Processing Neuron  3\n",
      "Values in Input   3\n",
      "Input  Value(0.5) Weight Value(-0.23653336516778944) Product Value(-0.11826668258389472) Previous Activation Value(0)\n",
      "New Activation Value(-0.11826668258389472)\n",
      "Input  Value(1) Weight Value(0.018092595814938273) Product Value(0.018092595814938273) Previous Activation Value(-0.11826668258389472)\n",
      "New Activation Value(-0.10017408676895645)\n",
      "Input  Value(-1.0) Weight Value(0.5805888443120657) Product Value(-0.5805888443120657) Previous Activation Value(-0.10017408676895645)\n",
      "New Activation Value(-0.6807629310810221)\n",
      "Bias Value(-0.2981630720614945)\n",
      "** Final Activation Value(-0.9789260031425167)  **\n",
      "** Tanh Squash  Value(-0.752600604346322)  **\n",
      ">>> Processing Layer  1\n",
      "    --- Processing Neuron  0\n",
      "Values in Input   4\n",
      "Input  Value(0.8983235713436679) Weight Value(-0.366441682366059) Product Value(-0.3291832007922601) Previous Activation Value(0)\n",
      "New Activation Value(-0.3291832007922601)\n",
      "Input  Value(-0.6409984175247144) Weight Value(0.6439097970588255) Product Value(-0.4127451609433671) Previous Activation Value(-0.3291832007922601)\n",
      "New Activation Value(-0.7419283617356272)\n",
      "Input  Value(0.08870142156682637) Weight Value(0.34201765484501867) Product Value(0.030337452185705317) Previous Activation Value(-0.7419283617356272)\n",
      "New Activation Value(-0.7115909095499219)\n",
      "Input  Value(-0.752600604346322) Weight Value(-0.5036751628717546) Product Value(0.37906623197151473) Previous Activation Value(-0.7115909095499219)\n",
      "New Activation Value(-0.33252467757840715)\n",
      "Bias Value(0.4379724264058984)\n",
      "** Final Activation Value(0.10544774882749125)  **\n",
      "** Tanh Squash  Value(0.10505864683034938)  **\n",
      "    --- Processing Neuron  1\n",
      "Values in Input   4\n",
      "Input  Value(0.8983235713436679) Weight Value(-0.5341524680540122) Product Value(-0.4798417527443147) Previous Activation Value(0)\n",
      "New Activation Value(-0.4798417527443147)\n",
      "Input  Value(-0.6409984175247144) Weight Value(0.5220947239083467) Product Value(-0.3346618918232529) Previous Activation Value(-0.4798417527443147)\n",
      "New Activation Value(-0.8145036445675675)\n",
      "Input  Value(0.08870142156682637) Weight Value(-0.4444135698859719) Product Value(-0.039420115412473845) Previous Activation Value(-0.8145036445675675)\n",
      "New Activation Value(-0.8539237599800413)\n",
      "Input  Value(-0.752600604346322) Weight Value(-0.15342687266425425) Product Value(0.11546915709008394) Previous Activation Value(-0.8539237599800413)\n",
      "New Activation Value(-0.7384546028899573)\n",
      "Bias Value(-0.6357519028783745)\n",
      "** Final Activation Value(-1.3742065057683317)  **\n",
      "** Tanh Squash  Value(-0.8796473201606909)  **\n",
      "    --- Processing Neuron  2\n",
      "Values in Input   4\n",
      "Input  Value(0.8983235713436679) Weight Value(0.10436345678979109) Product Value(0.0937521532211757) Previous Activation Value(0)\n",
      "New Activation Value(0.0937521532211757)\n",
      "Input  Value(-0.6409984175247144) Weight Value(-0.7708247304454754) Product Value(0.4940974324044643) Previous Activation Value(0.0937521532211757)\n",
      "New Activation Value(0.58784958562564)\n",
      "Input  Value(0.08870142156682637) Weight Value(-0.006340167987510137) Product Value(-0.0005623819134646337) Previous Activation Value(0.58784958562564)\n",
      "New Activation Value(0.5872872037121755)\n",
      "Input  Value(-0.752600604346322) Weight Value(-0.219071552168433) Product Value(0.16487338255704947) Previous Activation Value(0.5872872037121755)\n",
      "New Activation Value(0.7521605862692249)\n",
      "Bias Value(-0.11593475777548101)\n",
      "** Final Activation Value(0.6362258284937439)  **\n",
      "** Tanh Squash  Value(0.5623242845728643)  **\n",
      "    --- Processing Neuron  3\n",
      "Values in Input   4\n",
      "Input  Value(0.8983235713436679) Weight Value(0.4691487942897299) Product Value(0.42144742037792593) Previous Activation Value(0)\n",
      "New Activation Value(0.42144742037792593)\n",
      "Input  Value(-0.6409984175247144) Weight Value(-0.07350603888393681) Product Value(0.04711725460311362) Previous Activation Value(0.42144742037792593)\n",
      "New Activation Value(0.46856467498103954)\n",
      "Input  Value(0.08870142156682637) Weight Value(-0.7802592358676796) Product Value(-0.06921010341210886) Previous Activation Value(0.46856467498103954)\n",
      "New Activation Value(0.39935457156893067)\n",
      "Input  Value(-0.752600604346322) Weight Value(0.9378700820417687) Product Value(-0.7058415905429698) Previous Activation Value(0.39935457156893067)\n",
      "New Activation Value(-0.3064870189740391)\n",
      "Bias Value(-0.635178669888707)\n",
      "** Final Activation Value(-0.9416656888627462)  **\n",
      "** Tanh Squash  Value(-0.7359866139474663)  **\n",
      ">>> Processing Layer  2\n",
      "    --- Processing Neuron  0\n",
      "Values in Input   4\n",
      "Input  Value(0.10505864683034938) Weight Value(0.3882156416731124) Product Value(0.04078540999255298) Previous Activation Value(0)\n",
      "New Activation Value(0.04078540999255298)\n",
      "Input  Value(-0.8796473201606909) Weight Value(0.37283093924666866) Product Value(-0.32795973658132543) Previous Activation Value(0.04078540999255298)\n",
      "New Activation Value(-0.28717432658877245)\n",
      "Input  Value(0.5623242845728643) Weight Value(-0.8818853961896111) Product Value(-0.4959055744875801) Previous Activation Value(-0.28717432658877245)\n",
      "New Activation Value(-0.7830799010763525)\n",
      "Input  Value(-0.7359866139474663) Weight Value(0.5930932700205547) Product Value(-0.4365087075574584) Previous Activation Value(-0.7830799010763525)\n",
      "New Activation Value(-1.2195886086338108)\n",
      "Bias Value(-0.03497588823930142)\n",
      "** Final Activation Value(-1.2545644968731122)  **\n",
      "** Tanh Squash  Value(-0.8495586470703431)  **\n",
      "\n",
      "out [Value(-0.8495586470703431)]\n",
      "loss tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "x = [0.5, 1, -1.0] #-300\n",
    "n = MLP(3, [4, 4, 1])\n",
    "\n",
    "print('in', x)\n",
    "print('params', n.parameters())\n",
    "\n",
    "targets = torch.tensor([-0.25], dtype=torch.long)\n",
    "try:\n",
    "    out, loss = n(x, targets=targets)\n",
    "    print('')\n",
    "    print('out', out)\n",
    "    print('loss', loss)\n",
    "    #loss.backward()\n",
    "except IndexError as e:\n",
    "    print(f\"IndexError: {e}. Please ensure your target values are within the appropriate range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
